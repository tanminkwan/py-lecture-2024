{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 개요\n",
    "- 이미지에서 얼굴을 찾습니다.\n",
    "- 얼굴 이미지들간의 유사한 정도를 측정합니다.\n",
    "- 이미지에서 특정인의 얼굴을 찾아 다른 사람의 얼굴로 바꿉니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전준비\n",
    "#### 1. 필수 Library들을 설치\n",
    "##### 1-1. 필수 Library 목록\n",
    "- **NumPy**: 과학적 계산을 위한 파이썬 라이브러리. 고성능 다차원 배열 객체와 다양한 수학적 함수들을 제공하며, 데이터 분석, 머신 러닝, 신호 처리 등에서 널리 사용됨.\n",
    "\n",
    "- **OpenCV**: 이미지와 비디오 분석을 위한 컴퓨터 비전 라이브러리. 얼굴 검출, 객체 추적, 이미지 처리에 널리 사용됨.\n",
    "\n",
    "- **InsightFace**: 얼굴 인식 및 검출을 위한 오픈 소스 라이브러리. ArcFace 기반의 높은 정확도로 보안 및 인증 시스템에 활용됨.\n",
    "\n",
    "- **ONNX Runtime**: ONNX 형식의 딥러닝 모델을 빠르고 효율적으로 실행하는 런타임.\n",
    "\n",
    "##### 1-2. 필수 Library 설치\n",
    "- `Numpy`와 `OpenCV`는 `InsightFace` 설치 시 자동 설치됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install insightface onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-3. 필수 Library들 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # NumPy\n",
    "import cv2 # OpenCV\n",
    "import insightface # InsightFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. AI 모델 설치\n",
    "##### 2-1. Facial Anaysis 모델 설치\n",
    "- buffalo_l download from : \n",
    "  \n",
    "    https://github.com/deepinsight/insightface/releases\n",
    "\n",
    "- `C:\\models\\buffalo_l`에 `buffalo_l.zip` 을 unzip 하고 전역변수에 아래와 같이 저장 위치 명시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFALO_L_PATH = \"C:\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-2. Face Swap 모델 설치\n",
    "- Download `inswapper_128.onnx` :\n",
    "  \n",
    "    https://huggingface.co/ezioruan/inswapper_128.onnx/tree/main\n",
    "\n",
    "- 전역변수에 저장 위치 명시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSWAPPER_PATH = r\"C:\\models\\inswapper_128.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-3. 모델 설치 결과\n",
    "```bash\n",
    "C:\\models\n",
    "├── inswapper_128.onnx\n",
    "└── buffalo_l\n",
    "    ├── 1k3d68.onnx\n",
    "    ├── 2d106det.onnx\n",
    "    ├── det_10g.onnx\n",
    "    ├── genderage.onnx\n",
    "    └── w600k_r50.onnx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공부하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Yaw, Pitch, Roll\n",
    "**Yaw, Pitch, Roll**는 얼굴의 3D 방향을 나타내는 각도 값입니다:\n",
    "\n",
    "1. **Yaw (요)**: 얼굴이 좌우로 회전할 때의 각도를 나타냅니다.\n",
    "2. **Pitch (피치)**: 얼굴이 위나 아래를 볼 때의 각도를 나타냅니다.\n",
    "3. **Roll (롤)**: 머리가 한쪽으로 기울어졌을 때의 각도를 나타냅니다.\n",
    "\n",
    "![Link](./faces/yaw_pitch_roll.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 중요한 Class 들 불러오기\n",
    "- **`FaceAnalysis`**: 얼굴 분석을 위한 클래스입니다. 얼굴 감지 모델을 초기화하고, 입력 이미지에서 얼굴을 찾고 다양한 속성(성별, 나이, 얼굴 특징 등)을 추출하는 데 사용됩니다.\n",
    "\n",
    "- **`Face`**: 얼굴의 세부 정보를 담고 있는 객체입니다. 감지된 얼굴의 경계 상자(`bbox`), 랜드마크(`landmark`), 특징 벡터(`embedding`), 성별, 나이 등 얼굴에 관한 다양한 속성을 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insightface.app import FaceAnalysis\n",
    "from insightface.app.common import Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 분석하기: 이미지에서 얼굴을 찾고, 분석하고, 시각화하기\n",
    "#### 1. Class `Facama` 정의\n",
    "- 생성자 `__init__`: Face Analysis 모델을 메모리에 로드하고 AI 기능을 초기화합니다.\n",
    "- 메서드 `get_faces`: 입력 이미지에서 얼굴을 감지하고, 특징을 추출한 얼굴 정보(`Face` 객체들의 `list`)를 반환합니다.\n",
    "- 메서드 `detect_and_process_faces`: 이미지에서 얼굴을 감지하고, 각 얼굴에 사용자 정의 처리를 적용한 후 수정된 이미지를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class Facama:\n",
    "\n",
    "    # Face Analysis 모델을 메모리에 로드하고 AI 기능을 초기화\n",
    "    def __init__(\n",
    "            self, \n",
    "            name='buffalo_l', # 사용할 얼굴 인식 모델 이름.\n",
    "            root=BUFFALO_L_PATH, \n",
    "            ctx_id=-1, # 컨텍스트 ID. -1은 CPU, 0 이상은 GPU ID.\n",
    "            nms_thresh = 0.6,  # NMS 임계값.\n",
    "        ):\n",
    "\n",
    "        # FaceAnalysis 객체 초기화\n",
    "        self.app = FaceAnalysis(name=name, root=root) \n",
    "        self.app.prepare(ctx_id=ctx_id)\n",
    "\n",
    "        # NMS 임계값 설정\n",
    "        self.app.det_model.nms_thresh = nms_thresh\n",
    "\n",
    "    def get_faces(self, input_image: np.ndarray) -> list[Face]:\n",
    "\n",
    "        # 얼굴 임베딩 추출\n",
    "        faces = self.app.get(input_image)\n",
    "        if not faces:\n",
    "            raise ValueError(\"기준 이미지에서 얼굴을 검출하지 못했습니다.\")\n",
    "    \n",
    "        # 얼굴(들) 반환\n",
    "        return faces\n",
    "\n",
    "    def detect_and_process_faces(\n",
    "            self,\n",
    "            input_image: np.ndarray,\n",
    "            f: Callable[[np.ndarray, Face], None],\n",
    "        ) -> np.ndarray:\n",
    "\n",
    "        faces = self.get_faces(input_image)\n",
    "\n",
    "        # 검출된 얼굴 처리\n",
    "        for face in faces:\n",
    "            f(input_image, face)\n",
    "        \n",
    "        # 처리된 이미지를 반환\n",
    "        return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Class `Facama` 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facama 인스턴스 생성\n",
    "facama = Facama()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 얼굴에 Box 그리기\n",
    "- 얼굴 영역에 Box 그리는 콜백 함수(callback function) `draw_face_bbox` 정의\n",
    "- 함수 `detect_and_process_faces`에 원본 이미지, `draw_face_bbox`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 영역에 Box 그리기 함수 정의\n",
    "def draw_face_bbox(input_image: np.ndarray, face: Face) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    cv2.rectangle(input_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "\n",
    "# 이미지 파일 읽기\n",
    "img = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "    \n",
    "# 얼굴 검출 및 처리\n",
    "result_img = facama.detect_and_process_faces(\n",
    "    img,\n",
    "    draw_face_bbox,\n",
    ")\n",
    "    \n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_bbox.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 얼굴 별로 Yaw, Pitch, Roll 값 출력하기\n",
    "- Yaw, Pitch, Roll 값 출력하는 콜백 함수(callback function) `draw_ypr` 정의\n",
    "- 함수 `detect_and_process_faces`에 원본 이미지, `draw_ypr`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 별로 Yaw, Pitch, Roll 출력하기 함수 정의\n",
    "def draw_ypr(input_image: np.ndarray, face: Face) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "    \n",
    "    # YAW, PITCH, ROLL 계산\n",
    "    yaw, pitch, roll = face.pose[1], face.pose[0], face.pose[2]\n",
    "\n",
    "    # YAW, PITCH, ROLL 값 표시\n",
    "    if yaw is not None and pitch is not None and roll is not None:\n",
    "        cv2.putText(img, f\"YAW: {yaw:.1f}\", (bbox[0] + 5, bbox[1] + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (127, 127, 127), 2)\n",
    "        cv2.putText(img, f\"PITCH: {pitch:.1f}\", (bbox[0] + 5, bbox[1] + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (127, 127, 127), 2)\n",
    "        cv2.putText(img, f\"ROLL: {roll:.1f}\", (bbox[0] + 5, bbox[1] + 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (127, 127, 127), 2)\n",
    "\n",
    "# 이미지 파일 읽기\n",
    "img = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "    \n",
    "# 얼굴 검출 및 처리\n",
    "result_img = facama.detect_and_process_faces(\n",
    "    img,\n",
    "    draw_ypr\n",
    ")\n",
    "    \n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_ypr.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 얼굴 별로 랜드마크 점찍기\n",
    "- 랜드마크 점찍기 콜백 함수(callback function) `draw_landmarks` 정의\n",
    "- 함수 `detect_and_process_faces`에 원본 이미지, `draw_landmarks`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 랜드마크 표시 함수 정의\n",
    "def draw_landmarks(input_image: np.ndarray, face: Face) -> None:\n",
    "\n",
    "    # 각 랜드마크 좌표에 원 그리기\n",
    "    landmarks = face.landmark_2d_106\n",
    "    # Draw each landmark point\n",
    "    for i in range(landmarks.shape[0]):\n",
    "        point = landmarks[i]\n",
    "        x, y = int(point[0]), int(point[1])\n",
    "        cv2.circle(input_image, (x, y), 1, (0, 255, 0), -1)  # Green color, filled circle\n",
    "\n",
    "# 이미지 파일 읽기\n",
    "img = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "    \n",
    "# 얼굴 검출 및 처리\n",
    "result_img = facama.detect_and_process_faces(\n",
    "    img,\n",
    "    draw_landmarks\n",
    ")\n",
    "    \n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_landmarks.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 바꾸기: 특정인 얼굴 찾기, 얼굴 바꾸기\n",
    "#### 1. Class `Facama`에 메서드 `recognize_and_process_faces` 추가\n",
    "- 메서드 `recognize_and_process_faces`는 입력 이미지(`input_image`)를 받아 얼굴을 검출하고 기준 이미지(`ref_image`)의 얼굴과의 유사도를 계산하여 얼굴 인식을 수행합니다. 이후 전달받은 콜백 함수를 실행하여 입력 이미지를 가공하여 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def new_method(\n",
    "    self,\n",
    "    input_image: np.ndarray,\n",
    "    ref_image: np.ndarray,\n",
    "    f: Callable[[np.ndarray, Face, float, bool], None],\n",
    "    threshold: float = 0.4,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    입력 이미지를 받아 얼굴을 검출하고, 각 얼굴에 대해 지정된 함수 f를 적용하며,\n",
    "    기준 이미지(ref_image)의 얼굴과의 유사도를 계산하여 얼굴 인식을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (np.ndarray): 처리할 이미지.\n",
    "        ref_image (np.ndarray): 기준 얼굴 이미지.\n",
    "        f (Callable[[np.ndarray, Face, float, bool], None]): 각 얼굴에 대해 적용할 함수로,\n",
    "            인자로 input_image, face, similarity, is_match를 받습니다.\n",
    "        threshold (float): 얼굴 인식 임계값. 유사도가 이 값 이상이면 동일 인물로 판단합니다.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 처리된 이미지를 반환합니다.\n",
    "    \"\"\"\n",
    "    ref_embedding = self.get_faces(ref_image)[0].embedding  # 첫 번째 얼굴의 임베딩 사용\n",
    "\n",
    "    # 입력 이미지에서 얼굴 검출 및 임베딩 추출\n",
    "    faces = self.get_faces(input_image)\n",
    "\n",
    "    # 검출된 얼굴 처리\n",
    "    for face in faces:\n",
    "        # 대상 얼굴의 임베딩 추출은 이미 face.embedding에 있음\n",
    "\n",
    "        # 코사인 유사도 계산\n",
    "        similarity = cosine_similarity([ref_embedding], [face.embedding])[0][0]\n",
    "\n",
    "        # 유사도가 임계값 이상이면 동일 인물로 판단\n",
    "        is_match = similarity >= threshold\n",
    "\n",
    "        # 지정된 함수 호출\n",
    "        f(input_image, face, similarity, is_match)\n",
    "\n",
    "    # 처리된 이미지를 반환\n",
    "    return input_image\n",
    "\n",
    "# Facama 클래스에 동적으로 메서드 추가\n",
    "setattr(Facama, \"recognize_and_process_faces\", new_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 특정인 찾기\n",
    "- 유사도 수치를 출력하고 유사도가 높은 경우 얼굴에 녹색 Box를 그리는 콜백 함수(callback function) `process_recognized_face` 정의\n",
    "- Class `Facama`의 메서드 `recognize_and_process_faces`에 원본 이미지, 찾을 얼굴 이미지,`process_recognized_face`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기준 얼굴 이미지 로드 (뉴진스 멤버 : 하니)\n",
    "ref_image = cv2.imread(\"./faces/hanni.jpg\")\n",
    "if ref_image is None:\n",
    "    raise FileNotFoundError(f\"기준 이미지를 불러올 수 없습니다. 경로를 확인하세요: {ref_img_path}\")\n",
    "\n",
    "# 대상 이미지 로드 (뉴진스 5명)\n",
    "target_image = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "if target_image is None:\n",
    "    raise FileNotFoundError(f\"대상 이미지를 불러올 수 없습니다. 경로를 확인하세요: {target_img_path}\")\n",
    "\n",
    "# 얼굴 처리 함수 정의\n",
    "def process_recognized_face(input_image: np.ndarray, face: Face, similarity: float, is_match: bool) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    color = (0, 255, 0) if is_match else (0, 0, 255)  # 동일 인물이면 초록색, 아니면 빨간색\n",
    "    cv2.rectangle(input_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "    # 유사도 텍스트 표시\n",
    "    label = f\"{similarity:.2f}\"\n",
    "    cv2.putText(input_image, label, (bbox[0], bbox[1]-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "# 얼굴 인식 및 처리\n",
    "result_img = facama.recognize_and_process_faces(\n",
    "    target_image,\n",
    "    ref_image,\n",
    "    process_recognized_face,\n",
    "    threshold=0.4  # 임계값은 필요에 따라 조정하세요\n",
    ")\n",
    "\n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_recognition.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 특정인 얼굴을 다른 얼굴로 바꾸기\n",
    "- Face Swap 모델을 메모리에 로드하고 해당 AI 기능을 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Swap 모델을 메모리에 로드하고 AI 기능을 초기화\n",
    "swapper = insightface.model_zoo.get_model(\n",
    "            INSWAPPER_PATH, download=True, download_zip=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 얼굴을 다른 사람 얼굴로 바꾸는 콜백 함수(callback function) `swap_recognized_face` 정의\n",
    "- `Facama`의 메서드  `recognize_and_process_faces`에 원본 이미지, 찾을 얼굴 이미지,`swap_recognized_face`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기준 얼굴 이미지 로드 (뉴진스 멤버 : 하니)\n",
    "ref_image = cv2.imread(\"./faces/hanni.jpg\")\n",
    "\n",
    "# 대상 이미지 로드 (뉴진스 5명)\n",
    "target_image = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "\n",
    "# 바꿀 얼굴 이미지 로드 (텔런트 : 우현)\n",
    "swap_image = cv2.imread(\"./faces/woohyun.jpg\")\n",
    "\n",
    "swap_face = facama.get_faces(swap_image)[0]  # 첫 번째 얼굴\n",
    "\n",
    "# 얼굴 처리 함수 정의\n",
    "def swap_recognized_face(input_image: np.ndarray, face: Face, similarity: float, is_match: bool) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    color = (0, 255, 0) if is_match else (0, 0, 255)  # 동일 인물이면 초록색, 아니면 빨간색\n",
    "\n",
    "    if is_match:\n",
    "        input_image[:,:] = swapper.get(input_image, face, swap_face)\n",
    "\n",
    "    #cv2.rectangle(input_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "    # 유사도 텍스트 표시\n",
    "    label = f\"{similarity:.2f}\"\n",
    "    cv2.putText(input_image, label, (bbox[0], bbox[1]-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "# 얼굴 인식 및 처리\n",
    "result_img = facama.recognize_and_process_faces(\n",
    "    target_image, # (뉴진스 5명)\n",
    "    ref_image, # (뉴진스 멤버 : 하니)\n",
    "    swap_recognized_face,\n",
    "    threshold=0.4  # 임계값은 필요에 따라 조정하세요\n",
    ")\n",
    "\n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_swap.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 이미지의 모든 얼굴들을 특정 얼굴로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대상 이미지 로드 (뉴진스 5명)\n",
    "target_image = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "if target_image is None:\n",
    "    raise FileNotFoundError(f\"대상 이미지를 불러올 수 없습니다. 경로를 확인하세요: {target_img_path}\")\n",
    "\n",
    "# 얼굴 처리 함수 정의\n",
    "def swap_all(input_image: np.ndarray, face: Face) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    color = (0, 255, 0)\n",
    "\n",
    "    input_image[:,:] = swapper.get(input_image, face, swap_face)\n",
    "\n",
    "    label = \"Who?\"\n",
    "    cv2.putText(input_image, label, (bbox[0], bbox[1]-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "# 얼굴 검출 및 처리\n",
    "result_img = facama.detect_and_process_faces(\n",
    "    target_image,\n",
    "    swap_all\n",
    ")\n",
    "    \n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_swap_all.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (face2)",
   "language": "python",
   "name": "face2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
