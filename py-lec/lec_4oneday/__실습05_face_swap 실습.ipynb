{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 개요\n",
    "- 이미지에서 얼굴을 찾습니다.\n",
    "- 얼굴 이미지들간의 유사한 정도를 측정합니다.\n",
    "- 이미지에서 특정인의 얼굴을 찾아 다른 사람의 얼굴로 바꿉니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전준비\n",
    "#### 1. 필수 Library들을 설치합니다.\n",
    "- **OpenCV**: 이미지와 비디오 분석을 위한 컴퓨터 비전 라이브러리. 얼굴 검출, 객체 추적, 이미지 처리에 널리 사용됨.\n",
    "\n",
    "- **InsightFace**: 얼굴 인식 및 검출을 위한 오픈 소스 라이브러리. ArcFace 기반의 높은 정확도로 보안 및 인증 시스템에 활용됨.\n",
    "\n",
    "- **ONNX Runtime**: ONNX 형식의 딥러닝 모델을 빠르고 효율적으로 실행하는 런타임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: insightface in c:\\pypjt\\face2\\lib\\site-packages (0.7.3)\n",
      "Requirement already satisfied: onnxruntime in c:\\pypjt\\face2\\lib\\site-packages (1.19.2)\n",
      "Requirement already satisfied: numpy in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (2.1.2)\n",
      "Requirement already satisfied: onnx in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (1.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (4.66.5)\n",
      "Requirement already satisfied: requests in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (3.9.2)\n",
      "Requirement already satisfied: Pillow in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (11.0.0)\n",
      "Requirement already satisfied: scipy in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (1.5.2)\n",
      "Requirement already satisfied: scikit-image in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (0.24.0)\n",
      "Requirement already satisfied: easydict in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (1.13)\n",
      "Requirement already satisfied: cython in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (3.0.11)\n",
      "Requirement already satisfied: albumentations in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (1.4.18)\n",
      "Requirement already satisfied: prettytable in c:\\pypjt\\face2\\lib\\site-packages (from insightface) (3.11.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\pypjt\\face2\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\pypjt\\face2\\lib\\site-packages (from onnxruntime) (24.3.25)\n",
      "Requirement already satisfied: packaging in c:\\pypjt\\face2\\lib\\site-packages (from onnxruntime) (24.1)\n",
      "Requirement already satisfied: protobuf in c:\\pypjt\\face2\\lib\\site-packages (from onnxruntime) (5.28.2)\n",
      "Requirement already satisfied: sympy in c:\\pypjt\\face2\\lib\\site-packages (from onnxruntime) (1.13.1)\n",
      "Requirement already satisfied: PyYAML in c:\\pypjt\\face2\\lib\\site-packages (from albumentations->insightface) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in c:\\pypjt\\face2\\lib\\site-packages (from albumentations->insightface) (2.9.2)\n",
      "Requirement already satisfied: albucore==0.0.17 in c:\\pypjt\\face2\\lib\\site-packages (from albumentations->insightface) (0.0.17)\n",
      "Requirement already satisfied: eval-type-backport in c:\\pypjt\\face2\\lib\\site-packages (from albumentations->insightface) (0.2.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\pypjt\\face2\\lib\\site-packages (from albumentations->insightface) (4.10.0.84)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\pypjt\\face2\\lib\\site-packages (from scikit-image->insightface) (3.4.1)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\pypjt\\face2\\lib\\site-packages (from scikit-image->insightface) (2.36.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\pypjt\\face2\\lib\\site-packages (from scikit-image->insightface) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\pypjt\\face2\\lib\\site-packages (from scikit-image->insightface) (0.4)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\pypjt\\face2\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\pypjt\\face2\\lib\\site-packages (from matplotlib->insightface) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\pypjt\\face2\\lib\\site-packages (from matplotlib->insightface) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\pypjt\\face2\\lib\\site-packages (from matplotlib->insightface) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\pypjt\\face2\\lib\\site-packages (from matplotlib->insightface) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\pypjt\\face2\\lib\\site-packages (from matplotlib->insightface) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\pypjt\\face2\\lib\\site-packages (from matplotlib->insightface) (2.9.0.post0)\n",
      "Requirement already satisfied: wcwidth in c:\\pypjt\\face2\\lib\\site-packages (from prettytable->insightface) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\pypjt\\face2\\lib\\site-packages (from requests->insightface) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\pypjt\\face2\\lib\\site-packages (from requests->insightface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\pypjt\\face2\\lib\\site-packages (from requests->insightface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\pypjt\\face2\\lib\\site-packages (from requests->insightface) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\pypjt\\face2\\lib\\site-packages (from scikit-learn->insightface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\pypjt\\face2\\lib\\site-packages (from scikit-learn->insightface) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\pypjt\\face2\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\pypjt\\face2\\lib\\site-packages (from tqdm->insightface) (0.4.6)\n",
      "Requirement already satisfied: pyreadline3 in c:\\pypjt\\face2\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.5.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\pypjt\\face2\\lib\\site-packages (from pydantic>=2.7.0->albumentations->insightface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\pypjt\\face2\\lib\\site-packages (from pydantic>=2.7.0->albumentations->insightface) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\pypjt\\face2\\lib\\site-packages (from pydantic>=2.7.0->albumentations->insightface) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\pypjt\\face2\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install insightface onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. AI 모델 설치\n",
    "##### 2-1. Facial Anaysis 모델 설치\n",
    "- buffalo_l download from : \n",
    "  \n",
    "    https://github.com/deepinsight/insightface/releases\n",
    "\n",
    "- `C:\\models\\buffalo_l`에 `buffalo_l.zip` 을 unzip 하고 전역변수에 아래와 같이 저장 위치 명시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFALO_L_PATH = \"C:\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-2. Face Swap 모델 설치\n",
    "- Download `inswapper_128.onnx` :\n",
    "  \n",
    "    https://huggingface.co/ezioruan/inswapper_128.onnx/tree/main\n",
    "\n",
    "- 전역변수에 저장 위치 명시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSWAPPER_PATH = r\"C:\\models\\inswapper_128.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-3. 모델 설치 결과\n",
    "```bash\n",
    "C:\\models\n",
    "├── inswapper_128.onnx\n",
    "└── buffalo_l\n",
    "    ├── 1k3d68.onnx\n",
    "    ├── 2d106det.onnx\n",
    "    ├── det_10g.onnx\n",
    "    ├── genderage.onnx\n",
    "    └── w600k_r50.onnx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공부하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Yaw, Pitch, Roll\n",
    "**Yaw, Pitch, Roll**는 얼굴의 3D 방향을 나타내는 각도 값입니다:\n",
    "\n",
    "1. **Yaw (요)**: 얼굴이 좌우로 회전할 때의 각도를 나타냅니다.\n",
    "2. **Pitch (피치)**: 얼굴이 위나 아래를 볼 때의 각도를 나타냅니다.\n",
    "3. **Roll (롤)**: 머리가 한쪽으로 기울어졌을 때의 각도를 나타냅니다.\n",
    "\n",
    "![Link](./faces/yaw_pitch_roll.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 중요한 Class 들 불러오기\n",
    "- **`FaceAnalysis`**: 얼굴 분석을 위한 클래스입니다. 얼굴 감지 모델을 초기화하고, 입력 이미지에서 얼굴을 찾고 다양한 속성(성별, 나이, 얼굴 특징 등)을 추출하는 데 사용됩니다.\n",
    "\n",
    "- **`Face`**: 얼굴의 세부 정보를 담고 있는 객체입니다. 감지된 얼굴의 경계 상자(`bbox`), 랜드마크(`landmark`), 특징 벡터(`embedding`), 성별, 나이 등 얼굴에 관한 다양한 속성을 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\pypjt\\face2\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "from insightface.app import FaceAnalysis\n",
    "from insightface.app.common import Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 분석하기: 이미지에서 얼굴을 찾고, 분석하고, 시각화하기\n",
    "#### 1. Class `Facama` 정의\n",
    "- 생성자 `__init__`: Face Analysis 모델을 메모리에 로드하고 AI 기능을 초기화합니다.\n",
    "- 메서드 `get_faces`: 입력 이미지에서 얼굴을 감지하고, 특징을 추출한 얼굴 정보(`Face` 객체들의 `list`)를 반환합니다.\n",
    "- 메서드 `detect_and_process_faces`: 이미지에서 얼굴을 감지하고, 각 얼굴에 사용자 정의 처리를 적용한 후 수정된 이미지를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Callable\n",
    "\n",
    "class Facama:\n",
    "\n",
    "    # Face Analysis 모델을 메모리에 로드하고 AI 기능을 초기화\n",
    "    def __init__(\n",
    "            self, \n",
    "            name='buffalo_l', # 사용할 얼굴 인식 모델 이름.\n",
    "            root=BUFFALO_L_PATH, \n",
    "            ctx_id=-1, # 컨텍스트 ID. -1은 CPU, 0 이상은 GPU ID.\n",
    "            nms_thresh = 0.6,  # NMS 임계값.\n",
    "        ):\n",
    "\n",
    "        # FaceAnalysis 객체 초기화\n",
    "        self.app = FaceAnalysis(name=name, root=root) \n",
    "        self.app.prepare(ctx_id=ctx_id)\n",
    "\n",
    "        # NMS 임계값 설정\n",
    "        self.app.det_model.nms_thresh = nms_thresh\n",
    "\n",
    "    def get_faces(self, input_image: np.ndarray) -> list[Face]:\n",
    "\n",
    "        # 얼굴 임베딩 추출\n",
    "        faces = self.app.get(input_image)\n",
    "        if not faces:\n",
    "            raise ValueError(\"기준 이미지에서 얼굴을 검출하지 못했습니다.\")\n",
    "    \n",
    "        # 얼굴(들) 반환\n",
    "        return faces\n",
    "\n",
    "    def detect_and_process_faces(\n",
    "            self,\n",
    "            input_image: np.ndarray,\n",
    "            f: Callable[[np.ndarray, Face], None],\n",
    "        ) -> np.ndarray:\n",
    "\n",
    "        faces = self.get_faces(input_image)\n",
    "\n",
    "        # 검출된 얼굴 처리\n",
    "        for face in faces:\n",
    "            f(input_image, face)\n",
    "        \n",
    "        # 처리된 이미지를 반환\n",
    "        return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Class `Facama` 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\pypjt\\face2\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Facama 인스턴스 생성\n",
    "facama = Facama()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 얼굴에 Box 그리기\n",
    "- 얼굴 영역에 Box 그리는 콜백 함수(callback function) `draw_face_bbox` 정의\n",
    "- 함수 `detect_and_process_faces`에 원본 이미지, `draw_face_bbox`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(input_image, (bbox[\u001b[38;5;241m0\u001b[39m], bbox[\u001b[38;5;241m1\u001b[39m]), (bbox[\u001b[38;5;241m2\u001b[39m], bbox[\u001b[38;5;241m3\u001b[39m]), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 이미지 파일 읽기\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./faces/newJeans.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m이미지를 불러올 수 없습니다. 경로를 확인하세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 얼굴 영역에 Box 그리기 함수 정의\n",
    "def draw_face_bbox(input_image: np.ndarray, face: Face) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    cv2.rectangle(input_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "\n",
    "# 이미지 파일 읽기\n",
    "img = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"이미지를 불러올 수 없습니다. 경로를 확인하세요.\")\n",
    "    \n",
    "# 얼굴 검출 및 처리\n",
    "result_img = facama.detect_and_process_faces(\n",
    "    img,\n",
    "    draw_face_bbox,\n",
    ")\n",
    "    \n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_bbox.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 얼굴 별로 Yaw, Pitch, Roll 값 출력하기\n",
    "- Yaw, Pitch, Roll 값 출력하는 콜백 함수(callback function) `draw_ypr` 정의\n",
    "- 함수 `detect_and_process_faces`에 원본 이미지, `draw_ypr`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 별로 Yaw, Pitch, Roll 출력하기 함수 정의\n",
    "def draw_ypr(input_image: np.ndarray, face: Face) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "    \n",
    "    # YAW, PITCH, ROLL 계산\n",
    "    yaw, pitch, roll = face.pose[1], face.pose[0], face.pose[2]\n",
    "\n",
    "    # YAW, PITCH, ROLL 값 표시\n",
    "    if yaw is not None and pitch is not None and roll is not None:\n",
    "        cv2.putText(img, f\"YAW: {yaw:.1f}\", (bbox[0] + 5, bbox[1] + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (127, 127, 127), 2)\n",
    "        cv2.putText(img, f\"PITCH: {pitch:.1f}\", (bbox[0] + 5, bbox[1] + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (127, 127, 127), 2)\n",
    "        cv2.putText(img, f\"ROLL: {roll:.1f}\", (bbox[0] + 5, bbox[1] + 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (127, 127, 127), 2)\n",
    "\n",
    "# 이미지 파일 읽기\n",
    "img = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"이미지를 불러올 수 없습니다. 경로를 확인하세요.\")\n",
    "    \n",
    "# 얼굴 검출 및 처리\n",
    "result_img = facama.detect_and_process_faces(\n",
    "    img,\n",
    "    draw_ypr\n",
    ")\n",
    "    \n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_ypr.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 얼굴 별로 랜드마크 점찍기\n",
    "- 랜드마크 점찍기 콜백 함수(callback function) `draw_landmarks` 정의\n",
    "- 함수 `detect_and_process_faces`에 원본 이미지, `draw_landmarks`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 랜드마크 표시 함수 정의\n",
    "def draw_landmarks(input_image: np.ndarray, face: Face) -> None:\n",
    "\n",
    "    # 각 랜드마크 좌표에 원 그리기\n",
    "    landmarks = face.landmark_2d_106\n",
    "    # Draw each landmark point\n",
    "    for i in range(landmarks.shape[0]):\n",
    "        point = landmarks[i]\n",
    "        x, y = int(point[0]), int(point[1])\n",
    "        cv2.circle(input_image, (x, y), 1, (0, 255, 0), -1)  # Green color, filled circle\n",
    "\n",
    "# 이미지 파일 읽기\n",
    "img = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"이미지를 불러올 수 없습니다. 경로를 확인하세요.\")\n",
    "    \n",
    "# 얼굴 검출 및 처리\n",
    "result_img = facama.detect_and_process_faces(\n",
    "    img,\n",
    "    draw_landmarks\n",
    ")\n",
    "    \n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_landmarks.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 바꾸기: 특정인 얼굴 찾기, 얼굴 바꾸기\n",
    "#### 1. Class `Facama`에 메서드 `recognize_and_process_faces` 추가\n",
    "- 메서드 `recognize_and_process_faces`는 입력 이미지(`input_image`)를 받아 얼굴을 검출하고 기준 이미지(`ref_image`)의 얼굴과의 유사도를 계산하여 얼굴 인식을 수행합니다. 이후 전달받은 콜백 함수를 실행하여 입력 이미지를 가공하여 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Callable\n",
    "\n",
    "from insightface.app.common import Face\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def new_method(\n",
    "    self,\n",
    "    input_image: np.ndarray,\n",
    "    ref_image: np.ndarray,\n",
    "    f: Callable[[np.ndarray, Face, float, bool], None],\n",
    "    threshold: float = 0.4,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    입력 이미지를 받아 얼굴을 검출하고, 각 얼굴에 대해 지정된 함수 f를 적용하며,\n",
    "    기준 이미지(ref_image)의 얼굴과의 유사도를 계산하여 얼굴 인식을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (np.ndarray): 처리할 이미지.\n",
    "        ref_image (np.ndarray): 기준 얼굴 이미지.\n",
    "        f (Callable[[np.ndarray, Face, float, bool], None]): 각 얼굴에 대해 적용할 함수로,\n",
    "            인자로 input_image, face, similarity, is_match를 받습니다.\n",
    "        threshold (float): 얼굴 인식 임계값. 유사도가 이 값 이상이면 동일 인물로 판단합니다.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 처리된 이미지를 반환합니다.\n",
    "    \"\"\"\n",
    "    ref_embedding = self.get_faces(ref_image)[0].embedding  # 첫 번째 얼굴의 임베딩 사용\n",
    "\n",
    "    # 입력 이미지에서 얼굴 검출 및 임베딩 추출\n",
    "    faces = self.get_faces(input_image)\n",
    "\n",
    "    # 검출된 얼굴 처리\n",
    "    for face in faces:\n",
    "        # 대상 얼굴의 임베딩 추출은 이미 face.embedding에 있음\n",
    "\n",
    "        # 코사인 유사도 계산\n",
    "        similarity = cosine_similarity([ref_embedding], [face.embedding])[0][0]\n",
    "\n",
    "        # 유사도가 임계값 이상이면 동일 인물로 판단\n",
    "        is_match = similarity >= threshold\n",
    "\n",
    "        # 지정된 함수 호출\n",
    "        f(input_image, face, similarity, is_match)\n",
    "\n",
    "    # 처리된 이미지를 반환\n",
    "    return input_image\n",
    "\n",
    "# Facama 클래스에 동적으로 메서드 추가\n",
    "setattr(Facama, \"recognize_and_process_faces\", new_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 특정인 찾기\n",
    "- 유사도 수치를 출력하고 유사도가 높은 경우 얼굴에 녹색 Box를 그리는 콜백 함수(callback function) `process_recognized_face` 정의\n",
    "- Class `Facama`의 메서드 `recognize_and_process_faces`에 원본 이미지, 찾을 얼굴 이미지,`process_recognized_face`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기준 얼굴 이미지 로드 (뉴진스 멤버 : 하니)\n",
    "ref_image = cv2.imread(\"./faces/hanni.jpg\")\n",
    "if ref_image is None:\n",
    "    raise FileNotFoundError(f\"기준 이미지를 불러올 수 없습니다. 경로를 확인하세요: {ref_img_path}\")\n",
    "\n",
    "# 대상 이미지 로드 (뉴진스 5명)\n",
    "target_image = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "if target_image is None:\n",
    "    raise FileNotFoundError(f\"대상 이미지를 불러올 수 없습니다. 경로를 확인하세요: {target_img_path}\")\n",
    "\n",
    "# 얼굴 처리 함수 정의\n",
    "def process_recognized_face(input_image: np.ndarray, face: Face, similarity: float, is_match: bool) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    color = (0, 255, 0) if is_match else (0, 0, 255)  # 동일 인물이면 초록색, 아니면 빨간색\n",
    "    cv2.rectangle(input_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "    # 유사도 텍스트 표시\n",
    "    label = f\"{similarity:.2f}\"\n",
    "    cv2.putText(input_image, label, (bbox[0], bbox[1]-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "# 얼굴 인식 및 처리\n",
    "result_img = facama.recognize_and_process_faces(\n",
    "    target_image,\n",
    "    ref_image,\n",
    "    process_recognized_face,\n",
    "    threshold=0.4  # 임계값은 필요에 따라 조정하세요\n",
    ")\n",
    "\n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_recognition.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 특정인 얼굴을 다른 얼굴로 바꾸기\n",
    "- Face Swap 모델을 메모리에 로드하고 해당 AI 기능을 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import insightface\n",
    "\n",
    "# Face Swap 모델을 메모리에 로드하고 AI 기능을 초기화\n",
    "swapper = insightface.model_zoo.get_model(\n",
    "            INSWAPPER_PATH, download=True, download_zip=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 얼굴을 다른 사람 얼굴로 바꾸는 콜백 함수(callback function) `swap_recognized_face` 정의\n",
    "- `Facama`의 메서드  `recognize_and_process_faces`에 원본 이미지, 찾을 얼굴 이미지,`swap_recognized_face`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기준 얼굴 이미지 로드 (뉴진스 멤버 : 하니)\n",
    "ref_image = cv2.imread(\"./faces/hanni.jpg\")\n",
    "if ref_image is None:\n",
    "    raise FileNotFoundError(f\"기준 이미지를 불러올 수 없습니다. 경로를 확인하세요: {ref_img_path}\")\n",
    "\n",
    "# 대상 이미지 로드 (뉴진스 5명)\n",
    "target_image = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "if target_image is None:\n",
    "    raise FileNotFoundError(f\"대상 이미지를 불러올 수 없습니다. 경로를 확인하세요: {target_img_path}\")\n",
    "\n",
    "# 바꿀 얼굴 이미지 로드 (텔런트 : 우현)\n",
    "swap_image = cv2.imread(\"./faces/woohyun.jpg\")\n",
    "if swap_image is None:\n",
    "    raise FileNotFoundError(f\"대상 이미지를 불러올 수 없습니다. 경로를 확인하세요: {target_img_path}\")\n",
    "\n",
    "swap_face = facama.get_faces(swap_image)[0]  # 첫 번째 얼굴\n",
    "\n",
    "# 얼굴 처리 함수 정의\n",
    "def swap_recognized_face(input_image: np.ndarray, face: Face, similarity: float, is_match: bool) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    color = (0, 255, 0) if is_match else (0, 0, 255)  # 동일 인물이면 초록색, 아니면 빨간색\n",
    "\n",
    "    if is_match:\n",
    "        input_image[:,:] = swapper.get(input_image, face, swap_face)\n",
    "\n",
    "    #cv2.rectangle(input_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "    # 유사도 텍스트 표시\n",
    "    label = f\"{similarity:.2f}\"\n",
    "    cv2.putText(input_image, label, (bbox[0], bbox[1]-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "# 얼굴 인식 및 처리\n",
    "result_img = facama.recognize_and_process_faces(\n",
    "    target_image, # (뉴진스 5명)\n",
    "    ref_image, # (뉴진스 멤버 : 하니)\n",
    "    swap_recognized_face,\n",
    "    threshold=0.4  # 임계값은 필요에 따라 조정하세요\n",
    ")\n",
    "\n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_swap.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (face2)",
   "language": "python",
   "name": "face2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
