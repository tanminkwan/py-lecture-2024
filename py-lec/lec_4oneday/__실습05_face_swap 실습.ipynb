{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 개요\n",
    "- 이미지에서 얼굴을 찾습니다.\n",
    "- 얼굴 이미지들간의 유사한 정도를 측정합니다.\n",
    "- 이미지에서 특정인의 얼굴을 찾아 다른 사람의 얼굴로 바꿉니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전준비\n",
    "#### 1. 필수 Library들을 설치합니다.\n",
    "- **OpenCV**: 이미지와 비디오 분석을 위한 컴퓨터 비전 라이브러리. 얼굴 검출, 객체 추적, 이미지 처리에 널리 사용됨.\n",
    "\n",
    "- **InsightFace**: 얼굴 인식 및 검출을 위한 오픈 소스 라이브러리. ArcFace 기반의 높은 정확도로 보안 및 인증 시스템에 활용됨.\n",
    "\n",
    "- **ONNX Runtime**: ONNX 형식의 딥러닝 모델을 빠르고 효율적으로 실행하는 런타임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install insightface onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Facial Anaysis 모델 설치\n",
    "- buffalo_l download from : \n",
    "  \n",
    "    https://github.com/deepinsight/insightface/releases\n",
    "\n",
    "- unzip buffalo_l.zip on `C:\\Users\\<user>\\.insightface\\models\\buffalo_l`\n",
    "  \n",
    "#### 3. Face Swap 모델 설치\n",
    "- Download `inswapper_128.onnx` :\n",
    "  \n",
    "    https://huggingface.co/ezioruan/inswapper_128.onnx/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공부하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Yaw, Pitch, Roll\n",
    "**Yaw, Pitch, Roll**는 얼굴의 3D 방향을 나타내는 각도 값입니다:\n",
    "\n",
    "1. **Yaw (요)**: 얼굴이 좌우로 회전할 때의 각도를 나타냅니다.\n",
    "2. **Pitch (피치)**: 얼굴이 위나 아래를 볼 때의 각도를 나타냅니다.\n",
    "3. **Roll (롤)**: 머리가 한쪽으로 기울어졌을 때의 각도를 나타냅니다.\n",
    "\n",
    "![Link](./faces/yaw_pitch_roll.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 중요한 Class 들 불러오기\n",
    "- **`FaceAnalysis`**: 얼굴 분석을 위한 클래스입니다. 얼굴 감지 모델을 초기화하고, 입력 이미지에서 얼굴을 찾고 다양한 속성(성별, 나이, 얼굴 특징 등)을 추출하는 데 사용됩니다.\n",
    "\n",
    "- **`Face`**: 얼굴의 세부 정보를 담고 있는 객체입니다. 감지된 얼굴의 경계 상자(`bbox`), 랜드마크(`landmark`), 특징 벡터(`embedding`), 성별, 나이 등 얼굴에 관한 다양한 속성을 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\pypjt\\face2\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "from insightface.app import FaceAnalysis\n",
    "from insightface.app.common import Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 분석하기: 이미지에서 얼굴을 찾고, 분석하고, 시각화하기\n",
    "#### 1. 함수 `get_faces`\n",
    "- 함수 `get_faces`는 입력 이미지에서 얼굴을 감지하고, 특징을 추출한 얼굴 정보(`Face` 객체들의 `list`)를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_faces(input_image: np.ndarray) -> list[Face]:\n",
    "\n",
    "    # FaceAnalysis 객체 초기화\n",
    "    app = FaceAnalysis(name='buffalo_l') # 사용할 얼굴 인식 모델 이름.\n",
    "    app.prepare(ctx_id=-1) # 컨텍스트 ID. -1은 CPU, 0 이상은 GPU ID.\n",
    "\n",
    "    # NMS 임계값 설정\n",
    "    app.det_model.nms_thresh = 0.6 # NMS 임계값.\n",
    "\n",
    "    # 얼굴 임베딩 추출\n",
    "    faces = app.get(input_image)\n",
    "    if not faces:\n",
    "        raise ValueError(\"기준 이미지에서 얼굴을 검출하지 못했습니다.\")\n",
    "    \n",
    "    # 얼굴(들) 반환\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 함수 `detect_and_process_faces`\n",
    "- 함수 `detect_and_process_faces`는 이미지에서 얼굴을 감지하고, 각 얼굴에 사용자 정의 처리를 적용한 후 수정된 이미지를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "\n",
    "def detect_and_process_faces(\n",
    "    input_image: np.ndarray,\n",
    "    f: Callable[[np.ndarray, Face], None],\n",
    ") -> np.ndarray:\n",
    "\n",
    "    faces = get_faces(input_image)\n",
    "\n",
    "    # 검출된 얼굴 처리\n",
    "    for face in faces:\n",
    "        f(input_image, face)\n",
    "    \n",
    "    # 처리된 이미지를 반환\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 얼굴에 Box 그리기\n",
    "- 얼굴 영역에 Box 그리는 콜백 함수(callback function) `draw_face_bbox` 정의\n",
    "- 함수 `detect_and_process_faces`에 원본 이미지, `draw_face_bbox`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 영역에 Box 그리기 함수 정의\n",
    "def draw_face_bbox(input_image: np.ndarray, face: Face) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    cv2.rectangle(input_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "\n",
    "# 이미지 파일 읽기\n",
    "img = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"이미지를 불러올 수 없습니다. 경로를 확인하세요.\")\n",
    "    \n",
    "# 얼굴 검출 및 처리\n",
    "result_img = detect_and_process_faces(\n",
    "    img,\n",
    "    draw_face_bbox,\n",
    ")\n",
    "    \n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_bbox.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 얼굴 별로 Yaw, Pitch, Roll 값 출력하기\n",
    "- Yaw, Pitch, Roll 값 출력하는 콜백 함수(callback function) `draw_ypr` 정의\n",
    "- 함수 `detect_and_process_faces`에 원본 이미지, `draw_ypr`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 별로 Yaw, Pitch, Roll 출력하기 함수 정의\n",
    "def draw_ypr(input_image: np.ndarray, face: Face) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "    \n",
    "    # YAW, PITCH, ROLL 계산\n",
    "    yaw, pitch, roll = face.pose[1], face.pose[0], face.pose[2]\n",
    "\n",
    "    # YAW, PITCH, ROLL 값 표시\n",
    "    if yaw is not None and pitch is not None and roll is not None:\n",
    "        cv2.putText(img, f\"YAW: {yaw:.1f}\", (bbox[0] + 5, bbox[1] + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (127, 127, 127), 2)\n",
    "        cv2.putText(img, f\"PITCH: {pitch:.1f}\", (bbox[0] + 5, bbox[1] + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (127, 127, 127), 2)\n",
    "        cv2.putText(img, f\"ROLL: {roll:.1f}\", (bbox[0] + 5, bbox[1] + 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (127, 127, 127), 2)\n",
    "\n",
    "# 이미지 파일 읽기\n",
    "img = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"이미지를 불러올 수 없습니다. 경로를 확인하세요.\")\n",
    "    \n",
    "# 얼굴 검출 및 처리\n",
    "result_img = detect_and_process_faces(\n",
    "    img,\n",
    "    draw_ypr\n",
    ")\n",
    "    \n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_ypr.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 얼굴 별로 랜드마크 점찍기\n",
    "- 랜드마크 점찍기 콜백 함수(callback function) `draw_landmarks` 정의\n",
    "- 함수 `detect_and_process_faces`에 원본 이미지, `draw_landmarks`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 랜드마크 표시 함수 정의\n",
    "def draw_landmarks(input_image: np.ndarray, face: Face) -> None:\n",
    "\n",
    "    # 각 랜드마크 좌표에 원 그리기\n",
    "    landmarks = face.landmark_2d_106\n",
    "    # Draw each landmark point\n",
    "    for i in range(landmarks.shape[0]):\n",
    "        point = landmarks[i]\n",
    "        x, y = int(point[0]), int(point[1])\n",
    "        cv2.circle(input_image, (x, y), 1, (0, 255, 0), -1)  # Green color, filled circle\n",
    "\n",
    "# 이미지 파일 읽기\n",
    "img = cv2.imread(\"./faces/newJeans.jpg\")\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"이미지를 불러올 수 없습니다. 경로를 확인하세요.\")\n",
    "    \n",
    "# 얼굴 검출 및 처리\n",
    "result_img = detect_and_process_faces(\n",
    "    img,\n",
    "    draw_landmarks\n",
    ")\n",
    "    \n",
    "# 결과 이미지 저장\n",
    "output_path = 'result_landmarks.jpg'  # 저장할 경로와 파일 이름\n",
    "cv2.imwrite(output_path, result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 바꾸기: 특정인 얼굴 찾기, 얼굴 바꾸기\n",
    "#### 1. 함수 `recognize_and_process_faces`\n",
    "- 함수 `recognize_and_process_faces`는 입력 이미지를 받아 얼굴을 검출하고 기준 이미지(ref_image)의 얼굴과의 유사도를 계산하여 얼굴 인식을 수행합니다. 이후 전달받은 콜백 함수를 실행하여 입력 이미지를 가공하여 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "\n",
    "from insightface.app.common import Face\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recognize_and_process_faces(\n",
    "    input_image: np.ndarray,\n",
    "    ref_image: np.ndarray,\n",
    "    f: Callable[[np.ndarray, Face, float, bool], None],\n",
    "    threshold: float = 0.4,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    입력 이미지를 받아 얼굴을 검출하고, 각 얼굴에 대해 지정된 함수 f를 적용하며,\n",
    "    기준 이미지(ref_image)의 얼굴과의 유사도를 계산하여 얼굴 인식을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (np.ndarray): 처리할 이미지.\n",
    "        ref_image (np.ndarray): 기준 얼굴 이미지.\n",
    "        f (Callable[[np.ndarray, Face, float, bool], None]): 각 얼굴에 대해 적용할 함수로,\n",
    "            인자로 input_image, face, similarity, is_match를 받습니다.\n",
    "        threshold (float): 얼굴 인식 임계값. 유사도가 이 값 이상이면 동일 인물로 판단합니다.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 처리된 이미지를 반환합니다.\n",
    "    \"\"\"\n",
    "    ref_embedding = get_faces(ref_image)[0].embedding  # 첫 번째 얼굴의 임베딩 사용\n",
    "\n",
    "    # 입력 이미지에서 얼굴 검출 및 임베딩 추출\n",
    "    faces = get_faces(input_image)\n",
    "\n",
    "    # 검출된 얼굴 처리\n",
    "    for face in faces:\n",
    "        # 대상 얼굴의 임베딩 추출은 이미 face.embedding에 있음\n",
    "\n",
    "        # 코사인 유사도 계산\n",
    "        similarity = cosine_similarity([ref_embedding], [face.embedding])[0][0]\n",
    "\n",
    "        # 유사도가 임계값 이상이면 동일 인물로 판단\n",
    "        is_match = similarity >= threshold\n",
    "\n",
    "        # 지정된 함수 호출\n",
    "        f(input_image, face, similarity, is_match)\n",
    "\n",
    "    # 처리된 이미지를 반환\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 특정인 찾기\n",
    "- 유사도 수치를 출력하고 유사도가 높은 경우 얼굴에 녹색 Box를 그리는 콜백 함수(callback function) `process_recognized_face` 정의\n",
    "- 함수 `recognize_and_process_faces`에 원본 이미지, 찾을 얼굴 이미지,`process_recognized_face`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기준 얼굴 이미지 경로\n",
    "ref_img_path = \"./faces/hanni.jpg\"\n",
    "# 기준 얼굴 이미지 로드\n",
    "ref_image = cv2.imread(ref_img_path)\n",
    "if ref_image is None:\n",
    "    raise FileNotFoundError(f\"기준 이미지를 불러올 수 없습니다. 경로를 확인하세요: {ref_img_path}\")\n",
    "\n",
    "# 대상 이미지 로드\n",
    "target_img_path = \"./faces/newJeans.jpg\"\n",
    "target_image = cv2.imread(target_img_path)\n",
    "if target_image is None:\n",
    "    raise FileNotFoundError(f\"대상 이미지를 불러올 수 없습니다. 경로를 확인하세요: {target_img_path}\")\n",
    "\n",
    "# 얼굴 처리 함수 정의\n",
    "def process_recognized_face(input_image: np.ndarray, face: Face, similarity: float, is_match: bool) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    color = (0, 255, 0) if is_match else (0, 0, 255)  # 동일 인물이면 초록색, 아니면 빨간색\n",
    "    cv2.rectangle(input_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "    # 유사도 텍스트 표시\n",
    "    label = f\"{similarity:.2f}\"\n",
    "    cv2.putText(input_image, label, (bbox[0], bbox[1]-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "# 얼굴 인식 및 처리\n",
    "result_image = recognize_and_process_faces(\n",
    "    target_image,\n",
    "    ref_image,\n",
    "    process_recognized_face,\n",
    "    threshold=0.4  # 임계값은 필요에 따라 조정하세요\n",
    ")\n",
    "\n",
    "# 결과 이미지 표시\n",
    "cv2.imshow('Recognition Result', result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 특정인 얼굴을 다른 얼굴로 바꾸기\n",
    "- 얼굴을 다른 사람 얼굴로 바꾸는 콜백 함수(callback function) `swap_recognized_face` 정의\n",
    "- 함수 `recognize_and_process_faces`에 원본 이미지, 찾을 얼굴 이미지,`swap_recognized_face`를 전달하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import insightface\n",
    "\n",
    "# 기준 얼굴 이미지 경로\n",
    "ref_img_path = \"./faces/hanni.jpg\"\n",
    "# 기준 얼굴 이미지 로드\n",
    "ref_image = cv2.imread(ref_img_path)\n",
    "if ref_image is None:\n",
    "    raise FileNotFoundError(f\"기준 이미지를 불러올 수 없습니다. 경로를 확인하세요: {ref_img_path}\")\n",
    "\n",
    "# 대상 이미지 로드\n",
    "target_img_path = \"./faces/newJeans_01.jpg\"\n",
    "target_image = cv2.imread(target_img_path)\n",
    "if target_image is None:\n",
    "    raise FileNotFoundError(f\"대상 이미지를 불러올 수 없습니다. 경로를 확인하세요: {target_img_path}\")\n",
    "\n",
    "# 바꿀 얼굴 이미지 로드\n",
    "swapper = insightface.model_zoo.get_model(\n",
    "            'C:\\\\models\\\\inswapper_128.onnx', download=True, download_zip=True\n",
    "        )    \n",
    "swap_img_path = \"./faces/woohyun.jpg\"\n",
    "swap_image = cv2.imread(swap_img_path)\n",
    "swap_face = get_faces(swap_image)[0]  # 첫 번째 얼굴\n",
    "\n",
    "# 얼굴 처리 함수 정의\n",
    "def swap_recognized_face(input_image: np.ndarray, face: Face, similarity: float, is_match: bool) -> None:\n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    color = (0, 255, 0) if is_match else (0, 0, 255)  # 동일 인물이면 초록색, 아니면 빨간색\n",
    "\n",
    "    if is_match:\n",
    "        input_image[:,:] = swapper.get(input_image, face, swap_face)\n",
    "\n",
    "    #cv2.rectangle(input_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "    # 유사도 텍스트 표시\n",
    "    label = f\"{similarity:.2f}\"\n",
    "    cv2.putText(input_image, label, (bbox[0], bbox[1]-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "# 얼굴 인식 및 처리\n",
    "result_image = recognize_and_process_faces(\n",
    "    target_image,\n",
    "    ref_image,\n",
    "    swap_recognized_face,\n",
    "    threshold=0.4  # 임계값은 필요에 따라 조정하세요\n",
    ")\n",
    "\n",
    "# 결과 이미지 표시\n",
    "cv2.imshow('Recognition Result', result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (face2)",
   "language": "python",
   "name": "face2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
